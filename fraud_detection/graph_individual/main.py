import numpy as np
import torch
import random
from pyod.models.copod import COPOD
from pyod.models.iforest import IForest
from pyod.models.dif import DIF
from pyod.models.lof import LOF
from pyod.models.vae import VAE
from sklearn.metrics import roc_auc_score, average_precision_score
from sklearn.model_selection import train_test_split
from sklearn.model_selection import ParameterGrid
from sklearn.impute import SimpleImputer
from fraud_detection.graph_individual.utils import GraphDatasetGenerator

from pathlib import Path
import sys
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ PYTHONPATHì— ì¶”ê°€ (common ëª¨ë“ˆ ë¡œë“œìš©)
# ROOT = Path(__file__).resolve().parent
ROOT = Path(__file__).resolve().parent.parent
sys.path.append(str(ROOT))
from common.settings import SETTINGS, CHAIN, CHAIN_LABELS


from sklearn.metrics import roc_auc_score, average_precision_score

def evaluate_scores(y_true, scores):
    """ì´ìƒì¹˜ score ë°©í–¥ì„ ìë™ ë³´ì •í•´ì„œ AUC/APë¥¼ ê³„ì‚°"""
    auc = roc_auc_score(y_true, scores)
    ap = average_precision_score(y_true, scores)

    # ë§Œì•½ AUCê°€ 0.5ë³´ë‹¤ ë‚®ìœ¼ë©´, ì ìˆ˜ ë°©í–¥ì´ ë°˜ëŒ€ì¼ ê°€ëŠ¥ì„±ì´ í¬ë¯€ë¡œ ë’¤ì§‘ì–´ì„œ ë‹¤ì‹œ ê³„ì‚°
    if auc < 0.5:
        scores = -scores
        auc = roc_auc_score(y_true, scores)
        ap = average_precision_score(y_true, scores)

    return auc, ap


def is_unsupervised_deep_model(model):
    # í•„ìš”í•˜ë©´ AutoEncoder, ALAD ê°™ì€ ë‹¤ë¥¸ ë”¥ëŸ¬ë‹ ë¹„ì§€ë„ ëª¨ë¸ë„ ì—¬ê¸°ì— ì¶”ê°€ ê°€ëŠ¥
    return isinstance(model, VAE)

def eval_roc_auc(label, score):
    roc_auc = roc_auc_score(y_true=label, y_score=score)
    if roc_auc < 0.5:
        score = [1 - s for s in score]
        roc_auc = roc_auc_score(y_true=label, y_score=score)
    return roc_auc

def eval_average_precision(label, score):
    return average_precision_score(y_true=label, y_score=score)


def tune_and_find_best_params(model, param_grid, x_train, y_train, x_val, y_val):
    best_auc = -np.inf
    best_params = None

    for params in param_grid:   # ì´ë¯¸ list[dict] ì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ìˆœíšŒ
        model.set_params(**params)

        if isinstance(model, VAE):
            # VAEëŠ” ë¹„ì§€ë„ â†’ y ì‚¬ìš© X
            model.fit(x_train)
        else:
            model.fit(x_train, y_train)

        y_val_scores = model.decision_function(x_val)
        auc, ap = evaluate_scores(y_val, y_val_scores)

        if auc > best_auc:
            best_auc = auc
            best_params = params

    return best_params



# DIFì²˜ëŸ¼ â€œscore ë°©í–¥ì´ ë’¤ì§‘í˜€ ìˆëŠ” ëª¨ë¸â€ë„ ìë™ìœ¼ë¡œ AUC â‰¥ 0.5 ìª½ìœ¼ë¡œ ë§ì¶°ì„œ í‰ê°€í•©ë‹ˆë‹¤.
# ì‹¤ì œë¡œ ì›ë˜ repoì—ì„œ ë³´ì…¨ë˜ DIF AUC â‰ˆ 0.83 ì •ë„ì˜ ê°’ì— ë‹¤ì‹œ ê°€ê¹Œì›Œì§ˆ ê°€ëŠ¥ì„±ì´ í½ë‹ˆë‹¤.
# VAEë„ ë§Œì•½ score ë°©í–¥ì´ ê±°ê¾¸ë¡œë¼ë©´ ì•½ê°„ ê°œì„ ëœ ê°’ì´ ë‚˜ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
def evaluate_model_with_seeds(model, best_params, x, y, seeds):
    aucs, aps = [], []

    for seed in seeds:
        np.random.seed(seed)
        torch.manual_seed(seed)
        random.seed(seed)

        x_train, x_test, y_train, y_test = train_test_split(
            x, y, test_size=0.3, random_state=seed, stratify=y
        )

        model.set_params(**best_params)

        if isinstance(model, VAE):
            model.fit(x_train)
        else:
            model.fit(x_train, y_train)

        y_scores = model.decision_function(x_test)
        auc, ap = evaluate_scores(y_test, y_scores)

        aucs.append(auc)
        aps.append(ap)

    return np.mean(aucs), np.std(aucs), np.mean(aps), np.std(aps)




def main():
    # chain = 'polygon'
    print("Using chain:", CHAIN)   
    chain = CHAIN

    dataset_generator = GraphDatasetGenerator(f'./data/features/{chain}_basic_metrics_processed.csv')
    data_list = dataset_generator.get_pyg_data_list()
    x = torch.cat([data.x for data in data_list], dim=0).numpy()
    y = torch.cat([data.y.unsqueeze(0) if data.y.dim() == 0 else data.y for data in data_list]).numpy()

    # Handling NaN values
    imputer = SimpleImputer(strategy='mean')
    x = imputer.fit_transform(x)

    # Initial data split
    x_train_val, x_test, y_train_val, y_test = train_test_split(x, y, test_size=0.1, random_state=42)
    x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.1, random_state=42)

    num_features = x.shape[1]
    hidden_size = min(20, num_features // 2)
    try:
        models = {
            "COPOD": (
                COPOD(),
                [{"contamination": f} for f in np.linspace(0.01, 0.1, 10)]
            ),

            "Isolation Forest": (
                IForest(),
                [
                    {"n_estimators": n, "max_samples": s}
                    for n in [100, 200]
                    for s in [256, 512]
                ],
            ),

            "DIF": (
                DIF(),
                [{"contamination": f} for f in np.linspace(0.01, 0.05, 5)]
            ),

            "VAE": (
                VAE(
                    encoder_neuron_list=[hidden_size],
                    decoder_neuron_list=[hidden_size],
                    contamination=0.1,
                ),
                [
                    {
                        # ğŸ”§ ì—¬ê¸°: ë¦¬ìŠ¤íŠ¸ ì•ˆì— ì •ìˆ˜ë§Œ ë“¤ì–´ê°€ë„ë¡ ìˆ˜ì •
                        "encoder_neuron_list": [n],
                        "decoder_neuron_list": [n],
                        "contamination": f,
                    }
                    for n in [hidden_size // 2, hidden_size, hidden_size * 2]
                    for f in np.linspace(0.1, 0.3, 3)
                ],
            ),
        }

    except TypeError as e:
        raise RuntimeError(
            f"VAE ì´ˆê¸°í™” ì‹¤íŒ¨: í˜„ì¬ ì„¤ì¹˜ëœ pyod ë²„ì „ì˜ VAE ì¸ì ì´ë¦„ì„ í™•ì¸í•˜ì„¸ìš”. ì›ë³¸ ì—ëŸ¬: {e}"
        )

    seeds = [42, 43, 44]
    for model_name, (model, param_grid) in models.items():
        best_params = tune_and_find_best_params(model, param_grid, x_train, y_train, x_val, y_val)
        if best_params:
            avg_auc, std_auc, avg_ap, std_ap = evaluate_model_with_seeds(model, best_params, x, y, seeds)
            print(f"{model_name} Results: Average AUC = {avg_auc:.4f} Â± {std_auc:.4f}, Average AP = {avg_ap:.4f} Â± {std_ap:.4f}")
        else:
            print(f"{model_name} failed to find suitable parameters.")

if __name__ == "__main__":
    main()
