import argparse
import os
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import pandas as pd
from torch.utils.data import DataLoader
from sklearn.metrics import f1_score, roc_auc_score, precision_recall_curve, auc
import dgl
from dgl.dataloading import GraphDataLoader

# ê¸°ì¡´ ëª¨ë¸ ë° ë°ì´í„°ì…‹ import (í”„ë¡œì íŠ¸ êµ¬ì¡°ì— ë§ê²Œ ì¡°ì •)
from models import GoGModel  # ì‹¤ì œ ëª¨ë¸ í´ë˜ìŠ¤ëª…ìœ¼ë¡œ ë³€ê²½
from datasets import CryptoDataset  # ì‹¤ì œ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ëª…ìœ¼ë¡œ ë³€ê²½

def parse_args():
    parser = argparse.ArgumentParser(description='GoG Fraud Detection')
    
    # ë°ì´í„° ê´€ë ¨
    parser.add_argument('--data_dir', type=str, default='./data', help='Data directory')
    parser.add_argument('--dataset', type=str, default='elliptic', help='Dataset name')
    
    # ëª¨ë¸ ê´€ë ¨
    parser.add_argument('--hidden_dim', type=int, default=128, help='Hidden dimension')
    parser.add_argument('--num_layers', type=int, default=3, help='Number of GNN layers')
    parser.add_argument('--dropout', type=float, default=0.3, help='Dropout rate')
    
    # í•™ìŠµ ê´€ë ¨
    parser.add_argument('--epochs', type=int, default=100, help='Number of epochs')
    parser.add_argument('--batch_size', type=int, default=32, help='Batch size')
    parser.add_argument('--lr', type=float, default=0.001, help='Learning rate')
    parser.add_argument('--weight_decay', type=float, default=5e-4, help='Weight decay')
    
    # í‰ê°€ ë° ì €ì¥
    parser.add_argument('--save_dir', type=str, default='./checkpoints', help='Model save directory')
    parser.add_argument('--extract_scores', action='store_true', help='Extract scores for MC pipeline')
    parser.add_argument('--score_output', type=str, default='mc_input_scores.csv', help='Score output file')
    
    return parser.parse_args()


def evaluate_and_extract_scores(model, test_loader, device, save_path='mc_input_scores.csv'):
    """
    ëª¨ë¸ í‰ê°€ ë° MC íŒŒì´í”„ë¼ì¸ìš© Score ë°ì´í„° ì¶”ì¶œ
    """
    model.eval()
    
    all_node_ids = []
    all_labels = []
    all_scores = []
    
    batch_offset = 0  # ì „ì²´ ë…¸ë“œ ì¸ë±ìŠ¤ ì˜¤í”„ì…‹
    
    print("   ğŸ“¦ Processing batches...")
    
    with torch.no_grad():
        for batch_idx, batch_data in enumerate(test_loader):
            try:
                # ë°°ì¹˜ ë°ì´í„° ì²˜ë¦¬ (DGL ë°°ì¹˜ í˜•ì‹ í˜¸í™˜)
                if isinstance(batch_data, (list, tuple)) and len(batch_data) >= 2:
                    graphs, labels = batch_data,[object Object],, batch_data,[object Object],
                else:
                    graphs = batch_data
                    labels = graphs.ndata.get('label', None)
                
                graphs = graphs.to(device)
                if isinstance(labels, torch.Tensor):
                    labels = labels.to(device)
                
                # ëª¨ë¸ ì˜ˆì¸¡
                logits = model(graphs)
                
                # **í•µì‹¬ ìˆ˜ì •: ë°°ì¹˜ í¬ê¸° ì˜¬ë°”ë¥´ê²Œ ì¶”ì¶œ**
                current_batch_size = logits.shape,[object Object],  # âœ… logits.shape,[object Object], ì‚¬ìš©
                
                # í™•ë¥  ê³„ì‚° (fraud í´ë˜ìŠ¤ í™•ë¥ )
                probs = torch.softmax(logits, dim=-1)
                positive_scores = probs[:, 1].cpu().numpy()  # í´ë˜ìŠ¤ 1 (fraud)
                
                # Node ID ìƒì„±
                if hasattr(graphs, 'ndata') and 'node_id' in graphs.ndata:
                    node_ids = graphs.ndata['node_id'].cpu().numpy()
                else:
                    # ìˆœì°¨ ID í• ë‹¹ (MC íŒŒì´í”„ë¼ì¸ì—ì„œ ì‚¬ìš© ê°€ëŠ¥)
                    node_ids = np.arange(batch_offset, batch_offset + current_batch_size)
                
                # ì˜¤í”„ì…‹ ì—…ë°ì´íŠ¸
                batch_offset += current_batch_size
                
                # ë°ì´í„° ëˆ„ì 
                all_node_ids.extend(node_ids.tolist())
                all_labels.extend(labels.cpu().numpy().tolist() if labels is not None else [-1] * current_batch_size)
                all_scores.extend(positive_scores.tolist())
                
                # ì§„í–‰ë¥  ì¶œë ¥
                if (batch_idx + 1) % 50 == 0:
                    print(f"      Batch {batch_idx+1}/{len(test_loader)} ({batch_offset} samples)")
                    
            except Exception as e:
                print(f"âš ï¸  Batch {batch_idx} error: {e}")
                continue
    
    # CSV ì €ì¥
    df_scores = pd.DataFrame({
        'node_id': all_node_ids,
        'true_label': all_labels,
        'fraud_probability': all_scores
    })
    
    os.makedirs(os.path.dirname(save_path) or '.', exist_ok=True)
    df_scores.to_csv(save_path, index=False)
    
    print(f"\nâœ… ì™„ë£Œ! {save_path}")
    print(f"   ğŸ“ˆ ì´ ë…¸ë“œ: {len(df_scores):,}")
    print(f"   ğŸ”´ Fraud (label=1): {(df_scores['true_label'] == 1).sum():,}")
    print(f"   ğŸŸ¢ Normal (label=0): {(df_scores['true_label'] == 0).sum():,}")
    print(f"   ğŸ’¾ í‰ê·  Fraud í™•ë¥ : {df_scores['fraud_probability'].mean():.4f}")
    
    return df_scores


def train_epoch(model, train_loader, optimizer, criterion, device):
    """í•œ ì—í­ í•™ìŠµ"""
    model.train()
    total_loss = 0
    
    for batch_data in train_loader:
        if isinstance(batch_data, tuple):
            graphs, labels = batch_data
            graphs = graphs.to(device)
            labels = labels.to(device)
        else:
            graphs = batch_data.to(device)
            labels = graphs.ndata['label']
        
        optimizer.zero_grad()
        logits = model(graphs)
        loss = criterion(logits, labels)
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
    
    return total_loss / len(train_loader)


def evaluate(model, val_loader, device):
    """ê²€ì¦ ì„¸íŠ¸ í‰ê°€"""
    model.eval()
    all_preds = []
    all_labels = []
    all_probs = []
    
    with torch.no_grad():
        for batch_data in val_loader:
            if isinstance(batch_data, tuple):
                graphs, labels = batch_data
                graphs = graphs.to(device)
                labels = labels.to(device)
            else:
                graphs = batch_data.to(device)
                labels = graphs.ndata['label']
            
            logits = model(graphs)
            probs = torch.softmax(logits, dim=1)
            preds = torch.argmax(logits, dim=1)
            
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            all_probs.extend(probs[:, 1].cpu().numpy())
    
    # ë©”íŠ¸ë¦­ ê³„ì‚°
    f1 = f1_score(all_labels, all_preds, average='binary')
    auc_score = roc_auc_score(all_labels, all_probs)
    
    return f1, auc_score


def main(args):
    # 1. Device ì„¤ì •
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ”§ Using device: {device}")
    
    # 2. ë°ì´í„°ì…‹ ë¡œë“œ
    print(f"ğŸ“‚ Loading dataset from {args.data_dir}...")
    dataset = CryptoDataset(root=args.data_dir, name=args.dataset)
    
    # 3. Train/Val/Test ë¶„í• 
    # ë°ì´í„°ì…‹ í´ë˜ìŠ¤ì— split ë©”ì„œë“œê°€ ìˆë‹¤ê³  ê°€ì •
    if hasattr(dataset, 'get_idx_split'):
        split_idx = dataset.get_idx_split()
        train_idx, val_idx, test_idx = split_idx['train'], split_idx['valid'], split_idx['test']
    else:
        # ìˆ˜ë™ ë¶„í•  (8:1:1 ë¹„ìœ¨)
        num_samples = len(dataset)
        indices = np.random.permutation(num_samples)
        train_size = int(0.8 * num_samples)
        val_size = int(0.1 * num_samples)
        
        train_idx = indices[:train_size]
        val_idx = indices[train_size:train_size + val_size]
        test_idx = indices[train_size + val_size:]
    
    # Subset ìƒì„±
    train_dataset = torch.utils.data.Subset(dataset, train_idx)
    val_dataset = torch.utils.data.Subset(dataset, val_idx)
    test_dataset = torch.utils.data.Subset(dataset, test_idx)
    
    # 4. DataLoader ìƒì„±
    train_loader = GraphDataLoader(
        train_dataset,
        batch_size=args.batch_size,
        shuffle=True,
        drop_last=True,
        num_workers=4
    )
    
    val_loader = GraphDataLoader(
        val_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        drop_last=False,
        num_workers=4
    )
    
    test_loader = GraphDataLoader(
        test_dataset,
        batch_size=args.batch_size,
        shuffle=False,  # ìˆœì„œ ìœ ì§€ í•„ìˆ˜!
        drop_last=False,
        num_workers=4
    )
    
    print(f"âœ… Dataset split - Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}")
    
    # 5. ëª¨ë¸ ì´ˆê¸°í™”
    model = GoGModel(
        in_dim=dataset.num_features,
        hidden_dim=args.hidden_dim,
        out_dim=2,  # Binary classification
        num_layers=args.num_layers,
        dropout=args.dropout
    ).to(device)
    
    print(f"ğŸ§  Model initialized with {sum(p.numel() for p in model.parameters())} parameters")
    
    # 6. Optimizer ë° Loss
    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)
    criterion = nn.CrossEntropyLoss()
    
    # 7. í•™ìŠµ ë£¨í”„
    best_val_auc = 0
    best_model_path = os.path.join(args.save_dir, 'best_model.pth')
    os.makedirs(args.save_dir, exist_ok=True)
    
    print("\nğŸš€ Starting training...")
    for epoch in range(args.epochs):
        train_loss = train_epoch(model, train_loader, optimizer, criterion, device)
        val_f1, val_auc = evaluate(model, val_loader, device)
        
        print(f"Epoch {epoch+1}/{args.epochs} - Loss: {train_loss:.4f}, Val F1: {val_f1:.4f}, Val AUC: {val_auc:.4f}")
        
        # Best model ì €ì¥
        if val_auc > best_val_auc:
            best_val_auc = val_auc
            torch.save(model.state_dict(), best_model_path)
            print(f"   âœ¨ New best model saved! (AUC: {val_auc:.4f})")
    
    # 8. Best model ë¡œë“œ
    print(f"\nğŸ“¥ Loading best model from {best_model_path}")
    model.load_state_dict(torch.load(best_model_path))
    
    # 9. Test í‰ê°€
    test_f1, test_auc = evaluate(model, test_loader, device)
    print(f"\nğŸ¯ Test Results - F1: {test_f1:.4f}, AUC: {test_auc:.4f}")
    
    # 10. MC íŒŒì´í”„ë¼ì¸ìš© Score ì¶”ì¶œ
    if args.extract_scores:
        print("\nğŸ“Š Extracting scores for MC pipeline...")
        score_path = os.path.join(args.save_dir, args.score_output)
        evaluate_and_extract_scores(model, test_loader, device, save_path=score_path)
        print(f"âœ… MC pipeline input ready at: {score_path}")


if __name__ == "__main__":
    args = parse_args()
    main(args)